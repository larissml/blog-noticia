<!DOCTYPE html>
<html lang="pt-br">
	<head>
		<title>Lari News!</title>
		<meta http-equiv="Content-Type" content="charset=utf-8">
		<link rel="stylesheet" type="text/css" href="style.css" />
	</head>
	<body>		
		<div class="container">
			<nav>
				<div class="logo">
					<span>Lari Tech</span>
				</div>
				<ul>
					<li><a href="index.html" target="_self">Início</a></li>
					<li><a href="https://www.youtube.com/watch?v=jCzez_q8si0&list=TLPQMTcwNDIwMjST5a8ccwUjVQ&index=5" target="_self">Tecnologia</a></li>
					<li><a href="https://www.youtube.com/watch?v=j6tKIdt9K9M">Música</a></li>
				</ul>
			</nav>
		</div>
		<div class="centralizado">
		<h1>Inteligência artificial desperta discussões sobre confiabilidade e ética</h1>
	<figure>
		<img src="https://images.ctfassets.net/erznwkq1zetp/7sNlwI0YXGk36yLY7OaKTE/474c93a2572281e0601f1444214cc140/robot_Prancheta_1.jpg" alt="imagem">
	</figure>
		<p>Ao mesmo tempo que a inteligência artificial (IA) entusiasma aqueles que enxergam o seu potencial para solucionar problemas difíceis, o fato de a tecnologia estar recebendo tanta autonomia – e até tratamento pessoal – vem criando uma onda de preocupação. Por mais que algumas vezes essa inquietação pareça coisa de ficção científica, o uso da IA de fato carrega riscos potenciais que as organizações precisam estar prontas para gerenciar.

			Especialmente porque a inteligência artificial permite que máquinas tomem decisões e ações autônomas, as discussões sobre sua confiabilidade são mais urgentes do que aquelas relacionadas a outras tecnologias.
			
			Para ajudar a entender o grau de confiança em IA, o MIT, em conjunto com o SAS, pediu que 2.200 líderes de negócios, gestores e especialistas em todo o mundo dissessem quão confiáveis eles consideram os resultados e as recomendações de sistemas baseados em IA em dois diferentes contextos: em suas vidas pessoais, como consumidores; e no trabalho, ao interagir com os sistemas de IA em suas organizações.
			
			Em uma escala de 0 a 10, onde 10 é o mais confiável, a nota média registrada para os sistemas de IA pessoais foi 7, ante 6 para o uso nas empresas.
			Além do grau de confiabilidade, a análise também avaliou algumas preocupações dos executivos em relação aos riscos trazidos pela IA, e descobriu que as seis principais inquietudes dizem respeito a:</p>

			<ol>
				<li>Entrega de índices equivocados de retorno sobre o investimento</li>
				<li>Produção de informação de má qualidade</li>
				<li>Uso antiético da tecnologia</li>
				<li>Suporte a decisões tendenciosas, preconceituosas e potencialmente ilegais</li>
				<li>Produção de resultados que humanos não consigam explicar</li>
				<li>Incapacidade de gerenciar questões muito imprevisíveis</li>
			</ol>
			<h4>Novas ameaças demandam novas estruturas de gestão de risco</h4>
			<p>Para construir confiança em torno da IA é necessário gerenciar os riscos associados a ela. O levantamento do SAS tentou entender como as empresas estão fazendo isso. 

				De acordo com a pesquisa, cerca de metade delas tem trabalhado para criar estruturas organizacionais capazes de gerenciar os riscos associados à IA: 26% contam com uma equipe dedicada a criar políticas e gerenciar esses riscos, e 24% planejam criar essa estrutura. Naturalmente, as organizações que já utilizam algum tipo de recurso de inteligência artificial são mais propensas a contar com um time focado em estabelecer políticas e endereçar os riscos – 57% das empresas que fazem uso de IA em grande escala já o fazem, assim como 38% das que possuem sistemas pontuais de IA.
				
				As grandes empresas, com 5.000 funcionários ou mais, também tendem a endereçar os riscos da IA com mais efetividade: 34% delas já nomearam um grupo para isso. </p>
			<h4>Gestão diferente</h4>
			<p>A responsabilidade sobre a gestão de risco em IA é um pouco diferente dos demais processos de controle e mitigação de ameaças ao negócio. Aqui, ela tende a recair sobre o CIO, CTO ou o próprio CEO, assim como tende a ser compartilhada. A pesquisa indica que poucas organizações estão dando a responsabilidade sobre os riscos da IA a áreas que tradicionalmente gerenciam riscos, como a financeira ou jurídica.

				E, embora as aplicações de IA tenham grande potencial de causar prejuízos se forem mal utilizadas – ou se recomendarem decisões equivocadas –, apenas um em cada quatro líderes diz contar com um plano para remediar os danos. </p>
			<h4>Ética e conceitos preestabelecidos</h4>
			<p>A IA parece estar colocando na mesa discussões sobre ética. Para os especialistas de mercado e líderes de negócios, tornar os modelos de IA mais transparentes é algo alinhado com os esforços para garantir que essa poderosa tecnologia seja utilizada de maneira ética e que os desenvolvedores considerem que o modelo criado para um determinado fim pode, potencialmente, ser utilizado de modo inadequado para outra finalidade.

				As empresas parecem estar atentas a essa questão. De acordo com o estudo do SAS, 42% das organizações que possuem iniciativas de IA contam também com um quadro de profissionais dedicado a determinar caminhos éticos para o uso da tecnologia. Em 21% dessas organizações, especialistas em ética já foram contratados para compor o time.
				Além disso, questões de preconceitos também vêm à tona. Gerenciar os riscos de conceitos preestabelecidos em aplicativos de IA é fundamental para uma ciência de dados sólida. Isso porque ajustes inadequados podem comprometer modelos que preveem falhas em máquinas tão facilmente quanto podem distorcer modelos que impactam vidas humanas. Evidentemente, a gestão dos preconceitos é muito mais urgente nos modelos que fazem recomendações que afetam as pessoas, em que as consequências dos erros podem ser mais severas. Identificar e mitigar o risco de vieses requer que as organizações analisem os conjuntos de dados sob a ótica da diversidade e tragam diferentes pontos de vista à medida que os modelos são desenvolvidos.</p>
		</div>
			<footer>
			<div class="container-footer">
				<div class="contato">
					<p>Entre em contato:<br>E-mail: contato@seusite.com | Telefone: (00) 1234-5678</p>
				</div>
			</div>
		</footer>
	</body>
</html>